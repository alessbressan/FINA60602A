{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# industry returns\n",
    "df = pd.read_csv(str(Path().absolute()) + \"/data/48_Industry_Portfolios.CSV\", index_col = 0, skiprows = 11, nrows = 1182, header=0)\n",
    "df.index = pd.to_datetime(df.index, format = \"%Y%m\")\n",
    "df = df / 100\n",
    "\n",
    "# remove NAs\n",
    "mask = (df <= -0.99)\n",
    "df[mask] = np.nan\n",
    "\n",
    "# nb of industries dataframe\n",
    "nb_industries = pd.read_csv(str(Path().absolute()) + \"/data/48_Industry_Portfolios.CSV\", index_col = 0, skiprows = 2587, nrows = 1182, header=0)\n",
    "nb_industries.index = pd.to_datetime(nb_industries.index, format = \"%Y%m\")\n",
    "mask = (nb_industries <= -0.99)\n",
    "nb_industries[mask] = np.nan\n",
    "\n",
    "# average sizes dataframe\n",
    "avg_size = pd.read_csv(str(Path().absolute()) + \"/data/48_Industry_Portfolios.CSV\", index_col = 0, skiprows = 3773, nrows = 1182, header=0)\n",
    "avg_size.index = pd.to_datetime(avg_size.index, format = \"%Y%m\")\n",
    "mask = (avg_size <= -0.99)\n",
    "avg_size[mask] = np.nan\n",
    "\n",
    "# sum of BE / sum of ME dataframe\n",
    "be_over_me = pd.read_csv(str(Path().absolute()) + \"/data/48_Industry_Portfolios.CSV\", index_col = 0, skiprows = 4959, nrows = 99, header=0)\n",
    "be_over_me.index = pd.to_datetime(be_over_me.index, format = \"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1182, 48)\n",
      "(1177, 48)\n",
      "(1182, 48)\n"
     ]
    }
   ],
   "source": [
    "# market cap of each industry over time\n",
    "mkt_cap = nb_industries * avg_size\n",
    "\n",
    "# momentum with monthly data\n",
    "momentum = df.rolling(12).mean()\n",
    "\n",
    "# book value to market value\n",
    "# resample be_over_me to monthly data\n",
    "# we must first shift years since our \"factor year\" begins in July preventing us from grouping by years\n",
    "be_over_me.index = be_over_me.index + pd.DateOffset(months = 6)\n",
    "be_over_me = be_over_me.resample(\"MS\").ffill()\n",
    "\n",
    "# need to add missing portion of 2024 since data with shifted index is missing it\n",
    "extra_be_over_me = pd.DataFrame(np.repeat([be_over_me.iloc[-1].values], repeats = 5, axis = 0), \n",
    "                                index = pd.date_range(start=be_over_me.index[-1] + pd.DateOffset(months = 1), end='2024-12-01', freq='MS'), \n",
    "                                columns = be_over_me.columns)\n",
    "\n",
    "be_over_me = pd.concat([be_over_me, extra_be_over_me], axis = 0)\n",
    "mask = (be_over_me <= -99.99)\n",
    "be_over_me[mask] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(559, 48)\n",
      "(559, 48)\n",
      "(559, 48)\n",
      "(559, 48)\n"
     ]
    }
   ],
   "source": [
    "mkt_cap_ = mkt_cap.loc['1927-06-01':'1973-12-01']\n",
    "mkt_cap_norm = (mkt_cap_ - mkt_cap_.mean()) / mkt_cap_.std()\n",
    "print(mkt_cap_norm.shape)\n",
    "\n",
    "be_over_me_ = be_over_me.loc['1927-06-01':'1973-12-01']\n",
    "be_over_me_norm = (be_over_me_ - be_over_me_.mean()) / be_over_me_.std()\n",
    "print(be_over_me_norm.shape)\n",
    "\n",
    "momentum_ = momentum.loc['1927-06-01':'1973-12-01']\n",
    "momentum_norm = (momentum_ - momentum_.mean()) / momentum_.std()\n",
    "print(momentum_norm.shape)\n",
    "\n",
    "df_in = df.loc['1927-06-01':'1973-12-01']\n",
    "print(df_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRRA(wealth: float, gamma = 5):\n",
    "    \"\"\"\"\n",
    "    Constant Relative Risk Aversion Utility Function\n",
    "    ---\n",
    "    :param wealth: current wealth level of investor\n",
    "    :param gamma: risk aversion parameter\n",
    "    :return: CRRA utility level as given by functional form in Brandt et al. (2009), equation 15\n",
    "    \"\"\"\n",
    "\n",
    "    if gamma == 1:\n",
    "        return np.log(wealth)\n",
    "    else:\n",
    "        return ((1 + wealth) ** (1 - gamma)) / (1 - gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics = np.stack([mkt_cap_norm, be_over_me_norm, momentum_norm], axis= -1)  # 3 characteristics we're interested in\n",
    "weights = mkt_cap.iloc[-1]/ mkt_cap.iloc[-1].sum()  # weights of market portfolio (our benchmark)\n",
    "theta = np.array([-1.451, 3.606, 1.772])  # initial guess for theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(theta:np.ndarray, x:np.ndarray, rets:pd.DataFrame, weights:np.ndarray):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    accrued_wealth = 0.0\n",
    "    wealth = 0.0\n",
    "    for t in range(x.shape[0]):\n",
    "        rets_t1 = rets.iloc[t+1, :].values \n",
    "        x_t = x[t, :, :]\n",
    "        \n",
    "        valid_mask = ~np.isnan(rets_t1) & ~np.isnan(x_t).any(axis=1)\n",
    "        Nt = valid_mask.sum()\n",
    "        \n",
    "        if Nt > 0:\n",
    "            wealth += np.sum((weights[valid_mask] + (x_t[valid_mask] @ theta) / Nt) * rets_t1[valid_mask])\n",
    "        accrued_wealth += CRRA(wealth)\n",
    "    \n",
    "    return - accrued_wealth / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: Optimization terminated successfully\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: 6.494698443758094e-06\n",
       "       x: [-1.398e+01  4.366e+01  2.770e+01]\n",
       "     nit: 1\n",
       "     jac: [ 5.138e-07 -4.033e-06  5.735e-06]\n",
       "    nfev: 4\n",
       "    njev: 1"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = np.array([-1.398e+01,  4.366e+01, 2.770e+01]) # local solution found\n",
    "# init = theta\n",
    "response = minimize(objective, x0= init, args= (characteristics, df, weights), method= 'SLSQP')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find New Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15392515, -1.63226366, -2.58114127, -2.3781702 , -2.01743452,\n",
       "       -1.73431925, -2.48397976, -2.06254471, -2.80009338, -1.48297405,\n",
       "        1.91309059, -2.8094114 , -2.42926598, -0.22485848, -1.61746641,\n",
       "       -1.46347063, -0.9922424 , -1.85080179,  0.1245534 , -1.54020126,\n",
       "       -1.33436336, -1.30295921, -0.76151226, -0.1109189 , -0.20995246,\n",
       "        1.19035235,  0.43982617, -0.34550187, -0.7077866 , -1.19528758,\n",
       "       -0.97132281, -0.50712861, -1.87492782, -2.09387426, -2.02236567,\n",
       "       -1.11023043, -1.26536404, -0.7541866 , -1.89966462, -1.4040221 ,\n",
       "       -2.04357981, -2.08440924, -2.84235124, -2.03303118, -1.6115431 ,\n",
       "       -2.03087226, -2.68606177, -4.46803079])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_w = np.zeros(weights.shape)\n",
    "for i in range(len(weights)):\n",
    "    next_w[i] = weights[i] + (response.x @ characteristics[-1,i,:]) / (np.count_nonzero(~np.isnan(characteristics[-1,:,:]))/3)\n",
    "\n",
    "next_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52158756, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0339584 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.32453925, 0.11991479, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply equation 16\n",
    "def long_only_constraint(weights):\n",
    "    w_pos = np.clip(weights, 0, None) # set all negative to 0\n",
    "    return w_pos / np.sum(w_pos)\n",
    "\n",
    "l_w = long_only_constraint(next_w)\n",
    "l_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Sample Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load Out-of-Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(722, 48)\n",
      "(722, 48)\n",
      "(722, 48)\n",
      "(724, 48)\n"
     ]
    }
   ],
   "source": [
    "mkt_cap_ = mkt_cap.loc['1963-12-01':'2024-01-01']\n",
    "mkt_cap_norm = (mkt_cap_ - mkt_cap_.mean()) / mkt_cap_.std()\n",
    "print(mkt_cap_norm.shape)\n",
    "\n",
    "be_over_me_ = be_over_me.loc['1963-12-01':'2024-01-01']\n",
    "be_over_me_norm = (be_over_me_ - be_over_me_.mean()) / be_over_me_.std()\n",
    "print(be_over_me_norm.shape)\n",
    "\n",
    "momentum_ = momentum.loc['1963-12-01':'2024-01-01']\n",
    "momentum_norm = (momentum_ - momentum_.mean()) / momentum_.std()\n",
    "print(momentum_norm.shape)\n",
    "\n",
    "df_out = df.loc['1963-12-01':'2024-03-01']\n",
    "print(df_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.98,  43.66,  27.7 ])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat = np.stack([mkt_cap_norm, be_over_me_norm, momentum_norm], axis= -1)\n",
    "w_bar = mkt_cap.loc['1973-12-01']/ mkt_cap.loc['1973-12-01'].sum()\n",
    "theta = response.x\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [06:16<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "window_size = 120 # 10 years x 12 months = 120 timesteps\n",
    "next_w = np.zeros(w_bar.shape[0])\n",
    "monthly_rets = []\n",
    "\n",
    "for t in tqdm(range(window_size, x_hat.shape[0])): \n",
    "    x_hat_subset = x_hat[t-window_size:t, :, :]\n",
    "    df_out_subset = df_out.iloc[t-window_size:t+1]\n",
    "    w_bar = mkt_cap_.iloc[t]/ mkt_cap_.iloc[t].sum()\n",
    "\n",
    "    \n",
    "    # 1. Estimate Theta\n",
    "    res = minimize(objective, x0= theta, args= (x_hat_subset, df_out_subset, w_bar), method= 'SLSQP')\n",
    "    theta = res.x\n",
    "    # 2. Estimate Weights\n",
    "    denom = np.count_nonzero(~np.isnan(x_hat_subset[-1, :, :])) / 3\n",
    "    valid = ~np.isnan(x_hat_subset[-1, :, :]).any(axis=1)\n",
    "    next_w[valid] = weights[valid] + (x_hat_subset[-1, valid, :] @ theta) / denom\n",
    "\n",
    "    long_weights = long_only_constraint(next_w)\n",
    "    # 3. Estimate Next Month Returns\n",
    "    rets_clean = np.nan_to_num(df_out.iloc[t+1], nan=0)\n",
    "    # 4. Record Return\n",
    "    monthly_rets.append(long_weights @ rets_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.008217644528510122\n",
      "std: 0.05762429226886323\n",
      "sharpe: 0.1426072964188135\n"
     ]
    }
   ],
   "source": [
    "clean_rets = [r for r in monthly_rets if not np.isnan(r)]\n",
    "print(f'mean: {np.mean(clean_rets)}')\n",
    "print(f'std: {np.std(clean_rets)}')\n",
    "print(f'sharpe: {np.mean(clean_rets)/np.std(clean_rets)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
